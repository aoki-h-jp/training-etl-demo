requirements:
  title: "高速データ処理入門"
  target_audience:
    - データエンジニア初心者・中級者
    - データサイエンティスト
    - ビッグデータ処理に興味があるエンジニア
    - 大量のテキストデータを活用したマーケティング・意思決定に興味がある方
  duration: 45
  objectives:
    high_level:
      - 大規模データ（数GB～数十GB規模）を高速に処理するための基本概念を理解する
      - 日次バッチ処理と分散処理の必要性・メリットを把握する
      - AWS上での大規模データ分析アーキテクチャの概要（Glue, EMR, Step Functionsなど）を理解する
      - Amazon製品レビューを用いたETL・分析デモで、pandas（シングルスレッド）とpyspark.pandas（分散処理）の違いを体験する
    detailed:
      - 日次で数GB級の新着データが発生するユースケース（例：商品レビュー集計）を想定し、その課題を理解する
      - Amazon Product Reviews Datasetを題材に、ビジネスインサイト（レビュー評価・感情分析など）を得るためのETLフローを学ぶ
      - ローカル環境（pandas）と分散処理（pyspark.pandas）それぞれでデータを処理し、速度やメモリ使用量の違いを体感する

  prerequisites:
    environment:
      - Python 3.x インストール済み
      - Jupyter Notebook環境構築済み
    codebase:
      - pandas、numpyの基礎知識
      - PySpark（pyspark）の基本的なインストール・設定
      - （可能であれば）Amazon Product Reviews Dataset（一部抜粋でも可）のダウンロード済み

scenario:
  phases:
    1_overview_of_large_scale_processing:
      duration: 10
      steps:
        - "大規模データの日次バッチ処理の現場例を提示"
          details:
            - "Amazonの商品レビュー数は膨大で、日次でも数GB～数十GBの新着がありうる"
            - "シングルスレッドでは処理が追いつかない現実（処理時間の遅延、メモリ不足など）"
        - "ETL（Extract/Transform/Load）とバッチ処理の意義を再確認"
          details:
            - "Extract: 日次や週次で一括取得されるレビューやメタ情報"
            - "Transform: テキストクリーニング、感情分析用の下準備、集計など多段階の前処理"
            - "Load: 集計結果やクレンジング済みデータをDWHやデータレイクに格納"
        - "分散処理が必要な理由"
          details:
            - "数GB～数十GBのデータを迅速に処理し、翌朝にはダッシュボード・施策へ反映"
            - "マルチスレッド/複数ノードを活用することで大幅な処理時間短縮"
            - "ビジネス判断をタイムリーに行うためのスケーラビリティ・冗長性の確保"

    2_cloud_based_solution_overview:
      duration: 10
      steps:
        - "AWSにおける大規模データ分析アーキテクチャ概説"
          details:
            - "GlueやEMRを使ったSparkベースの分散処理で、日次バッチ分析をスケールアウト"
            - "Step Functionsを活用しETLフローをステップごとに管理すれば、拡張や保守が容易"
        - "Glue, EMR, Step Functionsの主要な特徴・メリット"
          details:
            - "AWS Glue: サーバレスSparkでETLを自動化、カタログ機能でスキーマ管理も容易"
            - "EMR: Hadoop/Sparkクラスタをマネージドで利用し、オンデマンドでノード追加/削除可能"
            - "Step Functions: ワークフロー制御とエラーハンドリングをノーコードで定義"
        - "バッチ処理のパイプライン例"
          details:
            - "S3上に毎日アップされるレビューをGlue/EMRでETL→RedshiftやS3パーティションにロード→BIツールで可視化"
            - "日次バッチの短時間完了を実現し、ビジネス側の意志決定を加速"

    3_demo_with_amazon_product_reviews:
      duration: 20
      steps:
        - "Amazon Product Reviews Datasetの概要紹介"
          details:
            - "複数のカテゴリがあり、合計数十GB超のデータ量"
            - "日次で新着レビューを集約すると、それだけでも数GB規模になる"
        - "Jupyter Notebookでのシングルスレッド処理（pandas）"
          details:
            - "CSV/JSONの一部（数百MB～1GB）を読み込む (`pd.read_csv()` など)"
            - "レビュー数、星評価、テキストの基本クリーニングを行い、欠損値処理や集計を実演"
            - "処理時間を計測し、大規模データではメモリ負荷や実行時間がネックになる点を確認"
        - "pyspark.pandasによる分散処理デモ"
          details:
            - "同じデータセットを `import pyspark.pandas as ps` を使って読み込み・集計"
            - "Sparkの並列処理でCPUコアをフル活用する様子を簡単に解説（RDDやExecutorの概念）"
            - "処理時間を比較し、pandasとの差を体感"
        - "ビジネスインサイトへの応用例"
          details:
            - "日次更新後の集計をダッシュボードに取り込み、翌朝にはレビュー状況を可視化"
            - "星評価や感情分析によるポジネガ判定を行い、マーケティング施策や商品改善に即活かす"
        - "次回/拡張の案内"
          details:
            - "ローカル環境のデモをAWS Glue・EMRに拡張すれば数GB～数十GBのフルデータも短時間で処理可能"
            - "Step Functionsを組み合わせ、ETLをステップ管理することで本番運用しやすくなる"

    conclusion:
      duration: 5
      steps:
        - "本日のまとめ（日次バッチ + 分散処理の重要性、pandas vs pyspark.pandasの比較）"
        - "質疑応答（データ規模に応じた設計方針、AWS活用例など）"
        - "次回の予告（クラウド上での実装デモ、スケーラビリティの実体験）"
